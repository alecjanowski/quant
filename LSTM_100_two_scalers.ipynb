{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This program predicts the last 20 (you can customize this) rows in a dependent data it loads. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What needs to be done next\n",
    "1. Improve the prediction accuracy\n",
    "<br> We need to find the optimal combinatino of n_input (see the code), the number of neurons in the LSTM layer, the number of epochs.\n",
    "<br>\n",
    "<br> \n",
    "2. Incorporate metrics (hit rate, IC)\n",
    "<br>\n",
    "<br>\n",
    "3. Test if this program works with the whole data. Right now, I have only tested with smaller data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program is based on the following Udemy course's Section 9 Video 80-85: <br> https://www.udemy.com/share/101WWMB0Ydc1ZQRn4=/\n",
    "<br> You are guaranteed the 30-day money-back, so you can buy and return it within 30 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other articles I referenced to make this program:\n",
    "<br> https://machinelearningmastery.com/how-to-use-the-timeseriesgenerator-for-time-series-forecasting-in-keras/\n",
    "<br> https://qiita.com/ta1nakamura/items/11b53669ce48219d6475\n",
    "<br> https://www.dlology.com/blog/how-to-use-keras-timeseriesgenerator-for-time-series-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "from tqdm import tqdm \n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "newTempDf2 = pd.read_csv(\"./TestData/Symbol_0.csv\")\n",
    "newTempDf2.drop([\"Time\"], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Symbol 0000 Dependent  Symbol 0000 Independent 00  \\\n",
      "0                   0.003462                   -0.004461   \n",
      "1                   0.001080                   -0.002892   \n",
      "2                   0.002744                    0.002572   \n",
      "3                   0.000468                    0.003104   \n",
      "4                   0.002065                    0.000371   \n",
      "...                      ...                         ...   \n",
      "42049               0.002159                    0.000553   \n",
      "42050               0.002557                    0.001036   \n",
      "42051               0.002884                   -0.000794   \n",
      "42052               0.004145                   -0.001964   \n",
      "42053               0.002540                   -0.002343   \n",
      "\n",
      "       Symbol 0000 Independent 01  Symbol 0000 Independent 02  \\\n",
      "0                       -0.004461                   -0.004461   \n",
      "1                       -0.002892                   -0.002892   \n",
      "2                       -0.001903                   -0.001903   \n",
      "3                        0.000193                    0.000193   \n",
      "4                        0.002946                   -0.001533   \n",
      "...                           ...                         ...   \n",
      "42049                   -0.000823                   -0.001048   \n",
      "42050                   -0.001402                   -0.002923   \n",
      "42051                   -0.000244                   -0.000616   \n",
      "42052                   -0.000932                   -0.003047   \n",
      "42053                   -0.003133                   -0.003966   \n",
      "\n",
      "       Symbol 0000 Independent 03  Symbol 0000 Independent 04  \\\n",
      "0                       -0.005021                    0.000000   \n",
      "1                       -0.006729                    0.000000   \n",
      "2                       -0.006753                    0.000000   \n",
      "3                       -0.003690                    0.000000   \n",
      "4                       -0.005400                    0.000000   \n",
      "...                           ...                         ...   \n",
      "42049                    0.005952                   -0.003848   \n",
      "42050                    0.006253                   -0.002326   \n",
      "42051                    0.002362                   -0.002875   \n",
      "42052                   -0.000554                   -0.004346   \n",
      "42053                   -0.002598                   -0.003903   \n",
      "\n",
      "       Symbol 0000 Independent 05  Symbol 0000 Independent 06  \\\n",
      "0                        0.000000                    0.000000   \n",
      "1                        0.000000                    0.000000   \n",
      "2                        0.000000                    0.000000   \n",
      "3                        0.000000                    0.000000   \n",
      "4                        0.000000                    0.000000   \n",
      "...                           ...                         ...   \n",
      "42049                    0.004729                    0.015147   \n",
      "42050                    0.007981                    0.014302   \n",
      "42051                    0.009491                    0.013224   \n",
      "42052                    0.007651                    0.011555   \n",
      "42053                    0.005096                    0.010345   \n",
      "\n",
      "       Symbol 0000 Independent 07  Symbol 0000 Independent 08  ...  \\\n",
      "0                       -0.006770                   -0.006770  ...   \n",
      "1                       -0.004114                   -0.004114  ...   \n",
      "2                        0.000451                   -0.005443  ...   \n",
      "3                        0.000110                   -0.002932  ...   \n",
      "4                       -0.000106                    0.000284  ...   \n",
      "...                           ...                         ...  ...   \n",
      "42049                    0.001117                   -0.000236  ...   \n",
      "42050                    0.000605                   -0.002350  ...   \n",
      "42051                   -0.002203                   -0.001106  ...   \n",
      "42052                   -0.002106                   -0.001540  ...   \n",
      "42053                   -0.002715                   -0.004928  ...   \n",
      "\n",
      "       Symbol 0000 Independent 10  Symbol 0000 Independent 11  \\\n",
      "0                       -0.008271                    0.000000   \n",
      "1                       -0.004673                    0.000000   \n",
      "2                       -0.005892                    0.000000   \n",
      "3                       -0.002837                    0.000000   \n",
      "4                       -0.005695                    0.000000   \n",
      "...                           ...                         ...   \n",
      "42049                    0.006585                    0.003855   \n",
      "42050                    0.005436                    0.005011   \n",
      "42051                    0.000082                    0.002889   \n",
      "42052                   -0.003076                    0.001948   \n",
      "42053                   -0.007156                    0.001804   \n",
      "\n",
      "       Symbol 0000 Independent 12  Symbol 0000 Independent 13  \\\n",
      "0                        0.000000                    0.000000   \n",
      "1                        0.000000                    0.000000   \n",
      "2                        0.000000                    0.000000   \n",
      "3                        0.000000                    0.000000   \n",
      "4                        0.000000                    0.000000   \n",
      "...                           ...                         ...   \n",
      "42049                    0.012009                    0.013723   \n",
      "42050                    0.015837                    0.012521   \n",
      "42051                    0.015344                    0.012592   \n",
      "42052                    0.013794                    0.012004   \n",
      "42053                    0.010920                    0.011619   \n",
      "\n",
      "       Symbol 0000 Independent 14  Symbol 0000 Independent 15  \\\n",
      "0                             0.0                         0.0   \n",
      "1                             0.0                         0.0   \n",
      "2                             0.0                         0.0   \n",
      "3                             0.0                         0.0   \n",
      "4                             0.0                         0.0   \n",
      "...                           ...                         ...   \n",
      "42049                         0.0                         0.0   \n",
      "42050                         0.0                         0.0   \n",
      "42051                         0.0                         0.0   \n",
      "42052                         0.0                         0.0   \n",
      "42053                         0.0                         0.0   \n",
      "\n",
      "       Symbol 0000 Independent 16  Symbol 0000 Independent 17  \\\n",
      "0                             0.0                         0.0   \n",
      "1                             0.0                         0.0   \n",
      "2                             0.0                         0.0   \n",
      "3                             0.0                         0.0   \n",
      "4                             0.0                         0.0   \n",
      "...                           ...                         ...   \n",
      "42049                         0.0                         0.0   \n",
      "42050                         0.0                         0.0   \n",
      "42051                         0.0                         0.0   \n",
      "42052                         0.0                         0.0   \n",
      "42053                         0.0                         0.0   \n",
      "\n",
      "       Symbol 0000 Independent 18  Symbol 0000 Independent 19  \n",
      "0                       -0.351299                   -1.485281  \n",
      "1                       -0.278004                   -1.519324  \n",
      "2                       -0.564827                   -1.890338  \n",
      "3                       -0.580793                   -1.806854  \n",
      "4                       -0.763975                   -1.971434  \n",
      "...                           ...                         ...  \n",
      "42049                    0.015280                   -0.421496  \n",
      "42050                   -0.116426                   -0.352963  \n",
      "42051                    0.048617                   -0.073806  \n",
      "42052                    0.218754                   -0.070836  \n",
      "42053                    0.362726                    0.055582  \n",
      "\n",
      "[42054 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(newTempDf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dask arrays into numpy arrays\n",
    "X = np.array(newTempDf2.iloc[:,1:])\n",
    "y = np.array(newTempDf2.iloc[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alec/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/alec/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/alec/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/alec/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/alec/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/alec/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale X and y, so that their ranges are within (0 ,1)\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "scaler_X.fit(X)\n",
    "scaler_y.fit(y)\n",
    "\n",
    "scaled_X = scaler_X.transform(X)\n",
    "scaled_y = scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and test\n",
    "scaled_X_train = scaled_X[0:5000, :]\n",
    "scaled_y_train = scaled_y[0:5000, :]\n",
    "# I just chose 14 because the first 13 rows are filled with 0 (NAs)\n",
    "\n",
    "scaled_X_test = scaled_X[30000:, :]\n",
    "scaled_y_test = scaled_y[30000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/alec/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1286: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  _pywrap_tensorflow.RegisterType(\"Mapping\", _collections.Mapping)\n",
      "/home/alec/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alec/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/home/alec/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/alec/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/object_identity.py:61: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  class ObjectIdentityDictionary(collections.MutableMapping):\n",
      "/home/alec/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/data_structures.py:374: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  class _ListWrapper(List, collections.MutableSequence,\n",
      "/home/alec/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:5506: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/alec/.keras/keras.json' mode='r' encoding='UTF-8'>\n",
      "  _config = json.load(open(_config_path))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/alec/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/alec/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alec/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a TimeseriesGenerator, which learns the dependency between data\n",
    "# In this case, the TimeseriesGenerator learns the dependency between scaled_X_train and scaled_y_train\n",
    "n_input = 7 # 7 rows in scaled_X_train predicts 1 row in scaled_y_train\n",
    "n_features = X.shape[1] # number of features—i.e. the number of colums of X\n",
    "\n",
    "generator = TimeseriesGenerator(scaled_X_train, scaled_y_train, length=n_input, batch_size=1)\n",
    "# \"length\": the number of the rows in scaled_X_train that are used for prediction\n",
    "# \"batch_size\": the number of the labels (1 row in scaled_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alec/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alec/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alec/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alec/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a LSTM layer to the neural network. 150 is the number of neurons in the layer. You need to play around with the number to find the best one. But 100 is a good number to try first.\n",
    "model.add(LSTM(100, activation = 'relu', input_shape=(n_input, n_features)))\n",
    "# Add a normal neural network layer, which contains y.shape[1] neurons\n",
    "model.add(Dense(y.shape[1]))\n",
    "# Loss function (cost function) is mse(Mean squared error)\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100)               48400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 48,501\n",
      "Trainable params: 48,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show the shape of the neural network model we just created\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alec/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/alec/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alec/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/10\n",
      "4993/4993 [==============================] - 41s 8ms/step - loss: 0.0194\n",
      "Epoch 2/10\n",
      "4993/4993 [==============================] - 40s 8ms/step - loss: 0.0181\n",
      "Epoch 3/10\n",
      "4182/4993 [========================>.....] - ETA: 6s - loss: 0.0179"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3578fd056902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the model to the TimeseriesGenerator 30 times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model to the TimeseriesGenerator 30 times\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "model.fit_generator(generator,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display how the loss decreases after each epoch\n",
    "loss = model.history.history['loss']\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs,loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable holds predicitons\n",
    "test_predictions = [] \n",
    "\n",
    "# Use last n_input points from the training set as a current_batch\n",
    "first_eval_batch = scaled_X_train[-n_input:, :]\n",
    "current_batch = first_eval_batch.reshape(1, n_input, n_features)\n",
    "# Reshape so that the shape of first_eval_batch matches that of X of TimeseriesGenerator\n",
    "\n",
    "# Predict len(scaled_y_test) datapoints\n",
    "for i in range(len(scaled_y_test)):\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "    \n",
    "    # Store the current prediction\n",
    "    test_predictions.append(current_pred)\n",
    "    \n",
    "    # Update the current batch \n",
    "    current_batch = np.append(current_batch[:,1:,:], [[scaled_X_test[i, :]]], axis=1)\n",
    "    #  axis = 1 means that [[current_pred] will be added to the second dimension of current_batch[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale back the predicted values so that they are in the orignal range \n",
    "true_predictions = scaler_y.inverse_transform(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted rows\n",
    "df_pred = pd.DataFrame(true_predictions)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original rows in the dependent data\n",
    "df_dependent = pd.DataFrame(y[30000:, :])\n",
    "df_dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
