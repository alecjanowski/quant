{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This program predicts the last 20 (you can customize this) rows in a dependent data it loads. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What needs to be done next\n",
    "1. Improve the prediction accuracy\n",
    "<br> We need to find the optimal combinatino of n_input (see the code), the number of neurons in the LSTM layer, the number of epochs.\n",
    "<br>\n",
    "<br> \n",
    "2. Incorporate metrics (hit rate, IC)\n",
    "<br>\n",
    "<br>\n",
    "3. Test if this program works with the whole data. Right now, I have only tested with smaller data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program is based on the following Udemy course's Section 9 Video 80-85: <br> https://www.udemy.com/share/101WWMB0Ydc1ZQRn4=/\n",
    "<br> You are guaranteed the 30-day money-back, so you can buy and return it within 30 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other articles I referenced to make this program:\n",
    "<br> https://machinelearningmastery.com/how-to-use-the-timeseriesgenerator-for-time-series-forecasting-in-keras/\n",
    "<br> https://qiita.com/ta1nakamura/items/11b53669ce48219d6475\n",
    "<br> https://www.dlology.com/blog/how-to-use-keras-timeseriesgenerator-for-time-series-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "from tqdm import tqdm \n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:11,  4.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "fileNames = [\"metaData\", \"xaa_independent_small\", \"xaa_dependent_small\"]\n",
    "frames = []\n",
    "for index, fileName in tqdm(enumerate(fileNames)):\n",
    "    frames.append(dd.read_csv(fileName + \".csv\", sep=\",\", sample = 2000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    frames[i] = frames[i].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is the independent data, and y is the dependent data.\n",
    "X = frames[1].iloc[:, 1:].to_dask_array(lengths=True) # \"lengths=True\" counts the number of rows in the frame.\n",
    "y = frames[2].iloc[:, 1:].to_dask_array(lengths=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dask arrays into numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale X and y, so that their ranges are within (0 ,1)\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "scaler_X.fit(X)\n",
    "scaler_y.fit(y)\n",
    "\n",
    "scaled_X = scaler_X.transform(X)\n",
    "scaled_y = scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and test\n",
    "scaled_X_train = scaled_X[14:80, :]\n",
    "scaled_y_train = scaled_y[14:80, :]\n",
    "# I just chose 14 because the first 13 rows are filled with 0 (NAs)\n",
    "\n",
    "scaled_X_test = scaled_X[80:, :]\n",
    "scaled_y_test = scaled_y[80:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py:5851: ResourceWarning: unclosed file <_io.TextIOWrapper name='/Users/daisuke/.keras/keras.json' mode='r' encoding='UTF-8'>\n",
      "  _config = json.load(open(_config_path))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/anaconda3/lib/python3.7/site-packages/socks.py:58: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Callable\n",
      "/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a TimeseriesGenerator, which learns the dependency between data\n",
    "# In this case, the TimeseriesGenerator learns the dependency between scaled_X_train and scaled_y_train\n",
    "n_input = 7 # 7 rows in scaled_X_train predicts 1 row in scaled_y_train\n",
    "n_features = X.shape[1] # number of features—i.e. the number of colums of X\n",
    "\n",
    "generator = TimeseriesGenerator(scaled_X_train, scaled_y_train, length=n_input, batch_size=1)\n",
    "# \"length\": the number of the rows in scaled_X_train that are used for prediction\n",
    "# \"batch_size\": the number of the labels (1 row in scaled_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a LSTM layer to the neural network. 150 is the number of neurons in the layer. You need to play around with the number to find the best one. But 100 is a good number to try first.\n",
    "model.add(LSTM(150, activation = 'relu', input_shape=(n_input, n_features)))\n",
    "# Add a normal neural network layer, which contains y.shape[1] neurons\n",
    "model.add(Dense(y.shape[1]))\n",
    "# Loss function (cost function) is mse(Mean squared error)\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 150)               13938600  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1154)              174254    \n",
      "=================================================================\n",
      "Total params: 14,112,854\n",
      "Trainable params: 14,112,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show the shape of the neural network model we just created\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:339: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  if not isinstance(values, collections.Sequence):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "59/59 [==============================] - 24s 399ms/step - loss: 0.2344\n",
      "Epoch 2/30\n",
      "59/59 [==============================] - 22s 377ms/step - loss: 0.0674\n",
      "Epoch 3/30\n",
      "59/59 [==============================] - 22s 372ms/step - loss: 0.0548\n",
      "Epoch 4/30\n",
      "59/59 [==============================] - 23s 386ms/step - loss: 0.0339\n",
      "Epoch 5/30\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.0189\n",
      "Epoch 6/30\n",
      "59/59 [==============================] - 23s 386ms/step - loss: 0.0148\n",
      "Epoch 7/30\n",
      "59/59 [==============================] - 23s 389ms/step - loss: 0.0142\n",
      "Epoch 8/30\n",
      "59/59 [==============================] - 23s 387ms/step - loss: 0.0140\n",
      "Epoch 9/30\n",
      "59/59 [==============================] - 23s 385ms/step - loss: 0.0140\n",
      "Epoch 10/30\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.0140\n",
      "Epoch 11/30\n",
      "59/59 [==============================] - 23s 386ms/step - loss: 0.0140\n",
      "Epoch 12/30\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.0140\n",
      "Epoch 13/30\n",
      "59/59 [==============================] - 22s 380ms/step - loss: 0.0140\n",
      "Epoch 14/30\n",
      "59/59 [==============================] - 23s 389ms/step - loss: 0.0140\n",
      "Epoch 15/30\n",
      "59/59 [==============================] - 23s 395ms/step - loss: 0.0140\n",
      "Epoch 16/30\n",
      "59/59 [==============================] - 24s 399ms/step - loss: 0.0139\n",
      "Epoch 17/30\n",
      "59/59 [==============================] - 23s 397ms/step - loss: 0.0140\n",
      "Epoch 18/30\n",
      "59/59 [==============================] - 24s 410ms/step - loss: 0.0140\n",
      "Epoch 19/30\n",
      "59/59 [==============================] - 23s 396ms/step - loss: 0.0140\n",
      "Epoch 20/30\n",
      "59/59 [==============================] - 25s 420ms/step - loss: 0.0140\n",
      "Epoch 21/30\n",
      "59/59 [==============================] - 25s 423ms/step - loss: 0.0139\n",
      "Epoch 22/30\n",
      "59/59 [==============================] - 29s 494ms/step - loss: 0.0139\n",
      "Epoch 23/30\n",
      "59/59 [==============================] - 29s 484ms/step - loss: 0.0139\n",
      "Epoch 24/30\n",
      "59/59 [==============================] - 25s 428ms/step - loss: 0.0140\n",
      "Epoch 25/30\n",
      "59/59 [==============================] - 28s 472ms/step - loss: 0.0140\n",
      "Epoch 26/30\n",
      "59/59 [==============================] - 25s 428ms/step - loss: 0.0139\n",
      "Epoch 27/30\n",
      "59/59 [==============================] - 25s 416ms/step - loss: 0.0140\n",
      "Epoch 28/30\n",
      "59/59 [==============================] - 24s 414ms/step - loss: 0.0140\n",
      "Epoch 29/30\n",
      "59/59 [==============================] - 24s 411ms/step - loss: 0.0139\n",
      "Epoch 30/30\n",
      "59/59 [==============================] - 24s 401ms/step - loss: 0.0139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c4d265e48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the TimeseriesGenerator 30 times\n",
    "model.fit_generator(generator,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display how the loss decreases after each epoch\n",
    "loss = model.history.history['loss']\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs,loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable holds predicitons\n",
    "test_predictions = [] \n",
    "\n",
    "# Use last n_input points from the training set as a current_batch\n",
    "first_eval_batch = scaled_X_train[-n_input:, :]\n",
    "current_batch = first_eval_batch.reshape(1, n_input, n_features)\n",
    "# Reshape so that the shape of first_eval_batch matches that of X of TimeseriesGenerator\n",
    "\n",
    "# Predict len(scaled_y_test) datapoints\n",
    "for i in range(len(scaled_y_test)):\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "    \n",
    "    # Store the current prediction\n",
    "    test_predictions.append(current_pred)\n",
    "    \n",
    "    # Update the current batch \n",
    "    current_batch = np.append(current_batch[:,1:,:], [[scaled_X_test[i, :]]], axis=1)\n",
    "    #  axis = 1 means that [[current_pred] will be added to the second dimension of current_batch[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale back the predicted values so that they are in the orignal range \n",
    "true_predictions = scaler_y.inverse_transform(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1144</th>\n",
       "      <th>1145</th>\n",
       "      <th>1146</th>\n",
       "      <th>1147</th>\n",
       "      <th>1148</th>\n",
       "      <th>1149</th>\n",
       "      <th>1150</th>\n",
       "      <th>1151</th>\n",
       "      <th>1152</th>\n",
       "      <th>1153</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005178</td>\n",
       "      <td>-0.001512</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>-0.001921</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>-0.001896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>-0.001390</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>-0.006723</td>\n",
       "      <td>-0.007584</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>-0.003027</td>\n",
       "      <td>-0.000860</td>\n",
       "      <td>-0.001988</td>\n",
       "      <td>-0.000724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005354</td>\n",
       "      <td>-0.001988</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.003965</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>-0.003911</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>-0.003927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>-0.002868</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>-0.006819</td>\n",
       "      <td>-0.007885</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>-0.006007</td>\n",
       "      <td>-0.001779</td>\n",
       "      <td>-0.003799</td>\n",
       "      <td>-0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.005417</td>\n",
       "      <td>-0.002159</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>-0.004624</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>-0.004655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>-0.003397</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>-0.006853</td>\n",
       "      <td>-0.007992</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>-0.007074</td>\n",
       "      <td>-0.002108</td>\n",
       "      <td>-0.004448</td>\n",
       "      <td>-0.001650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.002381</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>-0.005552</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>-0.005602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>-0.004086</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>-0.006898</td>\n",
       "      <td>-0.008133</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>-0.008464</td>\n",
       "      <td>-0.002536</td>\n",
       "      <td>-0.005292</td>\n",
       "      <td>-0.001969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.005434</td>\n",
       "      <td>-0.002206</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>-0.004821</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>-0.004856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>-0.003543</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>-0.006863</td>\n",
       "      <td>-0.008022</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.007369</td>\n",
       "      <td>-0.002199</td>\n",
       "      <td>-0.004627</td>\n",
       "      <td>-0.001718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.005315</td>\n",
       "      <td>-0.001882</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>-0.003469</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>-0.003476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>-0.002540</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>-0.006797</td>\n",
       "      <td>-0.007818</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>-0.005345</td>\n",
       "      <td>-0.001575</td>\n",
       "      <td>-0.003397</td>\n",
       "      <td>-0.001254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.005363</td>\n",
       "      <td>-0.002012</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>-0.004012</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>-0.004030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>-0.002942</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>-0.007900</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>-0.006158</td>\n",
       "      <td>-0.001825</td>\n",
       "      <td>-0.003891</td>\n",
       "      <td>-0.001440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.005297</td>\n",
       "      <td>-0.001833</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.003261</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>-0.003264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>-0.002385</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>-0.006787</td>\n",
       "      <td>-0.007786</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>-0.005034</td>\n",
       "      <td>-0.001479</td>\n",
       "      <td>-0.003208</td>\n",
       "      <td>-0.001183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.005408</td>\n",
       "      <td>-0.002134</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>-0.004521</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>-0.004550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>-0.003321</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>-0.006848</td>\n",
       "      <td>-0.007977</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>-0.006921</td>\n",
       "      <td>-0.002061</td>\n",
       "      <td>-0.004355</td>\n",
       "      <td>-0.001615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.005392</td>\n",
       "      <td>-0.002093</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>-0.004348</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>-0.004373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>-0.003192</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>-0.006840</td>\n",
       "      <td>-0.007951</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>-0.006661</td>\n",
       "      <td>-0.001980</td>\n",
       "      <td>-0.004197</td>\n",
       "      <td>-0.001556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.005429</td>\n",
       "      <td>-0.002193</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>-0.004766</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>-0.004800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>-0.003502</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>-0.006860</td>\n",
       "      <td>-0.008014</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>-0.007287</td>\n",
       "      <td>-0.002174</td>\n",
       "      <td>-0.004577</td>\n",
       "      <td>-0.001699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.005383</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>-0.004242</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>-0.004265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>-0.003114</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>-0.006835</td>\n",
       "      <td>-0.007935</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>-0.006503</td>\n",
       "      <td>-0.001932</td>\n",
       "      <td>-0.004100</td>\n",
       "      <td>-0.001520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.005528</td>\n",
       "      <td>-0.002461</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>-0.005886</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>-0.005943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>-0.004334</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>-0.006914</td>\n",
       "      <td>-0.008183</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>-0.008965</td>\n",
       "      <td>-0.002691</td>\n",
       "      <td>-0.005597</td>\n",
       "      <td>-0.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.005569</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.006374</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>-0.006348</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>-0.006415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>-0.004677</td>\n",
       "      <td>0.005936</td>\n",
       "      <td>-0.006936</td>\n",
       "      <td>-0.008253</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>-0.009658</td>\n",
       "      <td>-0.002905</td>\n",
       "      <td>-0.006018</td>\n",
       "      <td>-0.002242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.005415</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>-0.004608</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>-0.004638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>-0.003385</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>-0.006852</td>\n",
       "      <td>-0.007990</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>-0.007051</td>\n",
       "      <td>-0.002101</td>\n",
       "      <td>-0.004433</td>\n",
       "      <td>-0.001645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.005310</td>\n",
       "      <td>-0.001869</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>-0.003415</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>-0.003421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>-0.002499</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>-0.006795</td>\n",
       "      <td>-0.007810</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>-0.005264</td>\n",
       "      <td>-0.001550</td>\n",
       "      <td>-0.003348</td>\n",
       "      <td>-0.001236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.005262</td>\n",
       "      <td>-0.001739</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>-0.002871</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>-0.002866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>-0.002096</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>-0.006768</td>\n",
       "      <td>-0.007728</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>-0.004450</td>\n",
       "      <td>-0.001299</td>\n",
       "      <td>-0.002853</td>\n",
       "      <td>-0.001049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.005271</td>\n",
       "      <td>-0.001764</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>-0.002976</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>-0.002973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>-0.002174</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>-0.006774</td>\n",
       "      <td>-0.007743</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>-0.004607</td>\n",
       "      <td>-0.001347</td>\n",
       "      <td>-0.002948</td>\n",
       "      <td>-0.001085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.005296</td>\n",
       "      <td>-0.001832</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.003259</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>-0.003261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>-0.002383</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>-0.006787</td>\n",
       "      <td>-0.007786</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>-0.005030</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.001182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 1154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "0  -0.005178 -0.001512  0.000405  0.001999  0.001973  0.000096 -0.001921   \n",
       "1  -0.005354 -0.001988  0.001617  0.003965  0.001457  0.000253 -0.003911   \n",
       "2  -0.005417 -0.002159  0.002051  0.004669  0.001272  0.000309 -0.004624   \n",
       "3  -0.005499 -0.002381  0.002617  0.005586  0.001031  0.000382 -0.005552   \n",
       "4  -0.005434 -0.002206  0.002171  0.004864  0.001221  0.000324 -0.004821   \n",
       "5  -0.005315 -0.001882  0.001348  0.003529  0.001572  0.000218 -0.003469   \n",
       "6  -0.005363 -0.002012  0.001678  0.004065  0.001431  0.000261 -0.004012   \n",
       "7  -0.005297 -0.001833  0.001221  0.003323  0.001626  0.000201 -0.003261   \n",
       "8  -0.005408 -0.002134  0.001989  0.004569  0.001299  0.000301 -0.004521   \n",
       "9  -0.005392 -0.002093  0.001883  0.004397  0.001344  0.000287 -0.004348   \n",
       "10 -0.005429 -0.002193  0.002138  0.004810  0.001235  0.000320 -0.004766   \n",
       "11 -0.005383 -0.002067  0.001819  0.004292  0.001371  0.000279 -0.004242   \n",
       "12 -0.005528 -0.002461  0.002821  0.005917  0.000945  0.000408 -0.005886   \n",
       "13 -0.005569 -0.002571  0.003103  0.006374  0.000825  0.000445 -0.006348   \n",
       "14 -0.005415 -0.002155  0.002042  0.004654  0.001276  0.000308 -0.004608   \n",
       "15 -0.005310 -0.001869  0.001315  0.003475  0.001586  0.000214 -0.003415   \n",
       "16 -0.005262 -0.001739  0.000984  0.002938  0.001727  0.000171 -0.002871   \n",
       "17 -0.005271 -0.001764  0.001047  0.003041  0.001700  0.000179 -0.002976   \n",
       "18 -0.005296 -0.001832  0.001220  0.003321  0.001626  0.000201 -0.003259   \n",
       "\n",
       "        7         8         9     ...      1144      1145      1146      1147  \\\n",
       "0   0.001069  0.002525 -0.001896  ...  0.001015 -0.001390  0.001800 -0.006723   \n",
       "1   0.002083  0.001894 -0.003927  ...  0.002100 -0.002868  0.003659 -0.006819   \n",
       "2   0.002446  0.001667 -0.004655  ...  0.002489 -0.003397  0.004325 -0.006853   \n",
       "3   0.002919  0.001373 -0.005602  ...  0.002996 -0.004086  0.005192 -0.006898   \n",
       "4   0.002547  0.001605 -0.004856  ...  0.002597 -0.003543  0.004509 -0.006863   \n",
       "5   0.001858  0.002034 -0.003476  ...  0.001859 -0.002540  0.003246 -0.006797   \n",
       "6   0.002134  0.001862 -0.004030  ...  0.002155 -0.002942  0.003753 -0.006824   \n",
       "7   0.001752  0.002100 -0.003264  ...  0.001746 -0.002385  0.003052 -0.006787   \n",
       "8   0.002394  0.001700 -0.004550  ...  0.002434 -0.003321  0.004229 -0.006848   \n",
       "9   0.002306  0.001755 -0.004373  ...  0.002339 -0.003192  0.004067 -0.006840   \n",
       "10  0.002519  0.001622 -0.004800  ...  0.002567 -0.003502  0.004458 -0.006860   \n",
       "11  0.002252  0.001789 -0.004265  ...  0.002281 -0.003114  0.003968 -0.006835   \n",
       "12  0.003090  0.001267 -0.005943  ...  0.003178 -0.004334  0.005504 -0.006914   \n",
       "13  0.003325  0.001120 -0.006415  ...  0.003430 -0.004677  0.005936 -0.006936   \n",
       "14  0.002438  0.001673 -0.004638  ...  0.002481 -0.003385  0.004310 -0.006852   \n",
       "15  0.001830  0.002051 -0.003421  ...  0.001830 -0.002499  0.003195 -0.006795   \n",
       "16  0.001553  0.002223 -0.002866  ...  0.001533 -0.002096  0.002688 -0.006768   \n",
       "17  0.001607  0.002190 -0.002973  ...  0.001590 -0.002174  0.002785 -0.006774   \n",
       "18  0.001751  0.002100 -0.003261  ...  0.001745 -0.002383  0.003049 -0.006787   \n",
       "\n",
       "        1148      1149      1150      1151      1152      1153  \n",
       "0  -0.007584  0.001001 -0.003027 -0.000860 -0.001988 -0.000724  \n",
       "1  -0.007885  0.002280 -0.006007 -0.001779 -0.003799 -0.001406  \n",
       "2  -0.007992  0.002738 -0.007074 -0.002108 -0.004448 -0.001650  \n",
       "3  -0.008133  0.003334 -0.008464 -0.002536 -0.005292 -0.001969  \n",
       "4  -0.008022  0.002864 -0.007369 -0.002199 -0.004627 -0.001718  \n",
       "5  -0.007818  0.001996 -0.005345 -0.001575 -0.003397 -0.001254  \n",
       "6  -0.007900  0.002344 -0.006158 -0.001825 -0.003891 -0.001440  \n",
       "7  -0.007786  0.001862 -0.005034 -0.001479 -0.003208 -0.001183  \n",
       "8  -0.007977  0.002672 -0.006921 -0.002061 -0.004355 -0.001615  \n",
       "9  -0.007951  0.002561 -0.006661 -0.001980 -0.004197 -0.001556  \n",
       "10 -0.008014  0.002829 -0.007287 -0.002174 -0.004577 -0.001699  \n",
       "11 -0.007935  0.002493 -0.006503 -0.001932 -0.004100 -0.001520  \n",
       "12 -0.008183  0.003549 -0.008965 -0.002691 -0.005597 -0.002083  \n",
       "13 -0.008253  0.003847 -0.009658 -0.002905 -0.006018 -0.002242  \n",
       "14 -0.007990  0.002728 -0.007051 -0.002101 -0.004433 -0.001645  \n",
       "15 -0.007810  0.001961 -0.005264 -0.001550 -0.003348 -0.001236  \n",
       "16 -0.007728  0.001611 -0.004450 -0.001299 -0.002853 -0.001049  \n",
       "17 -0.007743  0.001679 -0.004607 -0.001347 -0.002948 -0.001085  \n",
       "18 -0.007786  0.001860 -0.005030 -0.001477 -0.003205 -0.001182  \n",
       "\n",
       "[19 rows x 1154 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted rows\n",
    "df_pred = pd.DataFrame(true_predictions)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1144</th>\n",
       "      <th>1145</th>\n",
       "      <th>1146</th>\n",
       "      <th>1147</th>\n",
       "      <th>1148</th>\n",
       "      <th>1149</th>\n",
       "      <th>1150</th>\n",
       "      <th>1151</th>\n",
       "      <th>1152</th>\n",
       "      <th>1153</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.003723</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.017026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.019410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>-0.012356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.004771</td>\n",
       "      <td>0.008046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.018362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>-0.010527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.005849</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>-0.012023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.004930</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>-0.009823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003927</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.015864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.011100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000283</td>\n",
       "      <td>-0.003109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.015190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>-0.013808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002235</td>\n",
       "      <td>-0.003259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.012017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>-0.012348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.001775</td>\n",
       "      <td>-0.003943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>-0.010857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.004562</td>\n",
       "      <td>-0.006240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>-0.010473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.004472</td>\n",
       "      <td>-0.001404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>-0.006676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.007538</td>\n",
       "      <td>0.007835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>-0.010552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.004114</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>-0.003350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.003501</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>-0.007675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.002434</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>-0.004604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.000883</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>-0.002626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.002350</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.003358</td>\n",
       "      <td>-0.002496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005724</td>\n",
       "      <td>-0.003570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.004314</td>\n",
       "      <td>-0.001071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>-0.006147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.006374</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>-0.007510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 1154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1     2     3         4     5     6     7         8     \\\n",
       "0  -0.003723  0.003140   0.0   0.0 -0.017026   0.0   0.0   0.0 -0.019410   \n",
       "1  -0.004771  0.008046   0.0   0.0 -0.010534   0.0   0.0   0.0 -0.018362   \n",
       "2  -0.005849  0.003937   0.0   0.0 -0.006963   0.0   0.0   0.0 -0.011600   \n",
       "3  -0.004930  0.000660   0.0   0.0 -0.011823   0.0   0.0   0.0 -0.011286   \n",
       "4  -0.003927  0.000850   0.0   0.0 -0.015864   0.0   0.0   0.0 -0.007966   \n",
       "5   0.000283 -0.003109   0.0   0.0 -0.015190   0.0   0.0   0.0 -0.006447   \n",
       "6   0.002235 -0.003259   0.0   0.0 -0.012017   0.0   0.0   0.0 -0.004741   \n",
       "7  -0.001775 -0.003943   0.0   0.0 -0.009679   0.0   0.0   0.0 -0.001499   \n",
       "8  -0.004562 -0.006240   0.0   0.0 -0.006883   0.0   0.0   0.0 -0.001054   \n",
       "9  -0.004472 -0.001404   0.0   0.0 -0.011133   0.0   0.0   0.0  0.000113   \n",
       "10 -0.007538  0.007835   0.0   0.0  0.015530   0.0   0.0   0.0  0.002781   \n",
       "11 -0.004114  0.005316   0.0   0.0  0.019378   0.0   0.0   0.0  0.008609   \n",
       "12 -0.003501  0.001912   0.0   0.0  0.017320   0.0   0.0   0.0  0.009895   \n",
       "13 -0.002434  0.004044   0.0   0.0  0.016724   0.0   0.0   0.0  0.011672   \n",
       "14 -0.000883  0.002372   0.0   0.0  0.016735   0.0   0.0   0.0  0.013486   \n",
       "15 -0.002350  0.000277   0.0   0.0  0.016696   0.0   0.0   0.0  0.010178   \n",
       "16 -0.003358 -0.002496   0.0   0.0  0.019789   0.0   0.0   0.0  0.010309   \n",
       "17 -0.004314 -0.001071   0.0   0.0  0.021079   0.0   0.0   0.0  0.008737   \n",
       "18 -0.006374  0.000849   0.0   0.0  0.021051   0.0   0.0   0.0  0.007425   \n",
       "\n",
       "    9     ...  1144  1145  1146      1147      1148  1149  1150  1151  1152  \\\n",
       "0    0.0  ...   0.0   0.0   0.0  0.006763 -0.012356   0.0   0.0   0.0   0.0   \n",
       "1    0.0  ...   0.0   0.0   0.0  0.009078 -0.010527   0.0   0.0   0.0   0.0   \n",
       "2    0.0  ...   0.0   0.0   0.0  0.002492 -0.012023   0.0   0.0   0.0   0.0   \n",
       "3    0.0  ...   0.0   0.0   0.0  0.000168 -0.009823   0.0   0.0   0.0   0.0   \n",
       "4    0.0  ...   0.0   0.0   0.0  0.000021 -0.011100   0.0   0.0   0.0   0.0   \n",
       "5    0.0  ...   0.0   0.0   0.0  0.001283 -0.013808   0.0   0.0   0.0   0.0   \n",
       "6    0.0  ...   0.0   0.0   0.0  0.000364 -0.012348   0.0   0.0   0.0   0.0   \n",
       "7    0.0  ...   0.0   0.0   0.0  0.000993 -0.010857   0.0   0.0   0.0   0.0   \n",
       "8    0.0  ...   0.0   0.0   0.0 -0.000823 -0.010473   0.0   0.0   0.0   0.0   \n",
       "9    0.0  ...   0.0   0.0   0.0  0.000401 -0.006676   0.0   0.0   0.0   0.0   \n",
       "10   0.0  ...   0.0   0.0   0.0  0.003861 -0.010552   0.0   0.0   0.0   0.0   \n",
       "11   0.0  ...   0.0   0.0   0.0  0.005974 -0.003350   0.0   0.0   0.0   0.0   \n",
       "12   0.0  ...   0.0   0.0   0.0 -0.000282 -0.007675   0.0   0.0   0.0   0.0   \n",
       "13   0.0  ...   0.0   0.0   0.0  0.002177 -0.004604   0.0   0.0   0.0   0.0   \n",
       "14   0.0  ...   0.0   0.0   0.0  0.004347 -0.002626   0.0   0.0   0.0   0.0   \n",
       "15   0.0  ...   0.0   0.0   0.0  0.006523 -0.001007   0.0   0.0   0.0   0.0   \n",
       "16   0.0  ...   0.0   0.0   0.0  0.005724 -0.003570   0.0   0.0   0.0   0.0   \n",
       "17   0.0  ...   0.0   0.0   0.0  0.005751 -0.006147   0.0   0.0   0.0   0.0   \n",
       "18   0.0  ...   0.0   0.0   0.0  0.006714 -0.007510   0.0   0.0   0.0   0.0   \n",
       "\n",
       "    1153  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "5    0.0  \n",
       "6    0.0  \n",
       "7    0.0  \n",
       "8    0.0  \n",
       "9    0.0  \n",
       "10   0.0  \n",
       "11   0.0  \n",
       "12   0.0  \n",
       "13   0.0  \n",
       "14   0.0  \n",
       "15   0.0  \n",
       "16   0.0  \n",
       "17   0.0  \n",
       "18   0.0  \n",
       "\n",
       "[19 rows x 1154 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original rows in the dependent data\n",
    "df_dependent = pd.DataFrame(y[80:, :])\n",
    "df_dependent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
